{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1e7KYQ1pmgRpQB5ORqrj-_GbPyXauPIbf",
      "authorship_tag": "ABX9TyNi2LDFW4bD4dGLYexZFFJy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spgauthaman/Gauthaman_assignment/blob/main/Gauthaman_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J34Vl2LqStlc",
        "outputId": "53bc45e0-771e-412b-fbab-9df8be236551"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.sparse import hstack\n",
        "\n",
        "# 1. Load Data\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/Mentorship/train.csv')\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/Mentorship/test.csv')\n",
        "\n",
        "# 2. Setup Preprocessing Tools\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def clean_text(text):\n",
        "    if pd.isna(text): return \"neutral\"\n",
        "    # Lowercase and remove punctuation/numbers\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', str(text).lower())\n",
        "    # Tokenize, remove stopwords, and lemmatize\n",
        "    tokens = [lemmatizer.lemmatize(w) for w in text.split() if w not in stop_words]\n",
        "    return \" \".join(tokens) if len(tokens) > 0 else \"neutral\"\n",
        "\n",
        "# 3. Apply Cleaning\n",
        "train_df['cleaned_review'] = train_df['Review Text'].apply(clean_text)\n",
        "test_df['cleaned_review'] = test_df['Review Text'].apply(clean_text)\n",
        "\n",
        "# 4. Handle Metadata (App Version Code)\n",
        "train_df['App Version Code'] = train_df['App Version Code'].fillna(0).astype(int)\n",
        "test_df['App Version Code'] = test_df['App Version Code'].fillna(0).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize TF-IDF\n",
        "tfidf_vec = TfidfVectorizer(ngram_range=(1, 2), max_features=5000)\n",
        "\n",
        "# Vectorize Text\n",
        "X_tfidf_train = tfidf_vec.fit_transform(train_df['cleaned_review'])\n",
        "X_tfidf_test = tfidf_vec.transform(test_df['cleaned_review'])\n",
        "\n",
        "# Combine TF-IDF with App Version Code\n",
        "X_final_train = hstack([X_tfidf_train, train_df[['App Version Code']].values])\n",
        "X_final_test = hstack([X_tfidf_test, test_df[['App Version Code']].values])\n",
        "\n",
        "# Target Variable (ensure the column name matches your CSV, e.g., 'Star Rating')\n",
        "# Replace 'Star Rating' with the actual column name for the 1-5 integer\n",
        "y_train = train_df['Star Rating']"
      ],
      "metadata": {
        "id": "yB84EqQfYzmh"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Setup Model and Parameters\n",
        "rf = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [10, 20, None],\n",
        "    'min_samples_split': [2, 5]\n",
        "}\n",
        "\n",
        "# 5-Fold Stratified Cross-Validation\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Grid Search\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=cv, scoring='accuracy', n_jobs=-1, verbose=1)\n",
        "grid_search.fit(X_final_train, y_train)\n",
        "\n",
        "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
        "print(f\"Best CV Accuracy: {grid_search.best_score_:.4f}\")\n",
        "\n",
        "# Detailed Validation Report\n",
        "best_model = grid_search.best_estimator_\n",
        "y_train_pred = best_model.predict(X_final_train)\n",
        "print(\"\\nInternal Validation Report:\")\n",
        "print(classification_report(y_train, y_train_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCiYxFtPY1SI",
        "outputId": "5fccf203-7718-4d4f-cd33-e957b816cabd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
            "Best Parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
            "Best CV Accuracy: 0.7007\n",
            "\n",
            "Internal Validation Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.99      0.99      1788\n",
            "           2       0.81      0.97      0.88       154\n",
            "           3       0.63      0.96      0.76       217\n",
            "           4       0.78      0.88      0.83       611\n",
            "           5       0.97      0.90      0.94      2923\n",
            "\n",
            "    accuracy                           0.93      5693\n",
            "   macro avg       0.84      0.94      0.88      5693\n",
            "weighted avg       0.94      0.93      0.94      5693\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on Test Data\n",
        "test_predictions = best_model.predict(X_final_test)\n",
        "\n",
        "# Create Submission DataFrame\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'Predicted_Rating': test_predictions\n",
        "})\n",
        "\n",
        "# Save to CSV\n",
        "submission.to_csv('predictions.csv', index=False)\n",
        "print(\"Final predictions saved to predictions.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKex3FHTaRJm",
        "outputId": "e16bfa80-2c33-48ff-eb4b-5fe41948436f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final predictions saved to predictions.csv\n"
          ]
        }
      ]
    }
  ]
}